{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration Timbre Transfer of Ensemble\n",
    "This notebook demonstrates how an ensemble sounds like if the timbre is transferred from virtual instruments from the SLAKH dataset to timbre that is generated by DDSP based on real world recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/workspace/ma/ma4/ddspzart/.venv/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.4) or chardet (5.0.0)/charset_normalizer (2.0.7) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "# Cut audio\n",
    "import numpy as np\n",
    "from dataloader_slakh import SlakhDataset\n",
    "import os\n",
    "# import numpy as np\n",
    "from IPython.display import Audio, display\n",
    "import matplotlib.pyplot as plt\n",
    "from pydub import AudioSegment\n",
    "import soundfile as sf\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/User/Documents/GitHub/uni/ddspzart/workspace_2/source_separation/data/OneExampleRecording/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/nicolas/workspace/ma/ma4/ddspzart/workspace_2/source_separation/0_timbre_transfer_ensemble.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nicolas/workspace/ma/ma4/ddspzart/workspace_2/source_separation/0_timbre_transfer_ensemble.ipynb#ch0000002?line=0'>1</a>\u001b[0m \u001b[39m# Get Audio Snippet\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nicolas/workspace/ma/ma4/ddspzart/workspace_2/source_separation/0_timbre_transfer_ensemble.ipynb#ch0000002?line=1'>2</a>\u001b[0m TARGET \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mTrumpet\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/nicolas/workspace/ma/ma4/ddspzart/workspace_2/source_separation/0_timbre_transfer_ensemble.ipynb#ch0000002?line=2'>3</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m SlakhDataset(target\u001b[39m=\u001b[39;49mTARGET, seq_duration\u001b[39m=\u001b[39;49m\u001b[39m5.0\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nicolas/workspace/ma/ma4/ddspzart/workspace_2/source_separation/0_timbre_transfer_ensemble.ipynb#ch0000002?line=4'>5</a>\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nicolas/workspace/ma/ma4/ddspzart/workspace_2/source_separation/0_timbre_transfer_ensemble.ipynb#ch0000002?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m([train_dataset\u001b[39m.\u001b[39mtracks[i]\u001b[39m.\u001b[39mtargets[j]\u001b[39m.\u001b[39minstrument \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nicolas/workspace/ma/ma4/ddspzart/workspace_2/source_separation/0_timbre_transfer_ensemble.ipynb#ch0000002?line=6'>7</a>\u001b[0m     \u001b[39mlen\u001b[39m(train_dataset\u001b[39m.\u001b[39mtracks[i]\u001b[39m.\u001b[39mtargets))])\n",
      "File \u001b[0;32m~/workspace/ma/ma4/ddspzart/workspace_2/source_separation/dataloader_slakh.py:138\u001b[0m, in \u001b[0;36mSlakhDataset.__init__\u001b[0;34m(self, split, target, seq_duration)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget \u001b[39m=\u001b[39m target\n\u001b[1;32m    137\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset \u001b[39m=\u001b[39m mirdata\u001b[39m.\u001b[39minitialize(\u001b[39m'\u001b[39m\u001b[39mslakh\u001b[39m\u001b[39m'\u001b[39m, DATASET_FOLDER)\n\u001b[0;32m--> 138\u001b[0m track_folders \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(os\u001b[39m.\u001b[39;49mlistdir(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mDATASET_FOLDER\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00msplit\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    139\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_tracks \u001b[39m=\u001b[39m []\n\u001b[1;32m    140\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_tracks \u001b[39m=\u001b[39m [Track(\u001b[39mint\u001b[39m(id_str[\u001b[39m-\u001b[39m\u001b[39m5\u001b[39m:]), split\u001b[39m=\u001b[39msplit,\n\u001b[1;32m    141\u001b[0m                          seq_duration\u001b[39m=\u001b[39mseq_duration) \u001b[39mfor\u001b[39;00m id_str \u001b[39min\u001b[39;00m track_folders]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/User/Documents/GitHub/uni/ddspzart/workspace_2/source_separation/data/OneExampleRecording/train'"
     ]
    }
   ],
   "source": [
    "# Get Audio Snippet\n",
    "TARGET = \"Trumpet\"\n",
    "train_dataset = SlakhDataset(target=TARGET, seq_duration=5.0) #TODO does not work on my machine\n",
    "\n",
    "i = 0\n",
    "print([train_dataset.tracks[i].targets[j].instrument for j in range(\n",
    "    len(train_dataset.tracks[i].targets))])\n",
    "# print(train_dataset.tracks[0].targets)\n",
    "print([train_dataset.tracks[i].targets[j].instrument for j in [3, -6, -1]])\n",
    "\n",
    "audios = [train_dataset.tracks[i].targets[j].get_total_audio()\n",
    "          for j in [2, -7, -5, -2]]\n",
    "\n",
    "# Cut Audio\n",
    "t = np.linspace(0, 4+0.06/60*100, len(audios[0]))\n",
    "t_1 = 3 + (.19 / 60*100)\n",
    "t_2 = 3 + (.4 / 60*100)\n",
    "t_cut_ = t[t > t_1]\n",
    "t_cut = t_cut_[t_cut_ < t_2]\n",
    "\n",
    "audios_cut = []\n",
    "titles = [\"Trumpet\", \"Trombone\", \"Guitar\", \"Flute\"]\n",
    "for i, a in enumerate(audios):\n",
    "    cut = a[t > t_1]\n",
    "    cut = np.array(cut[t_cut_ < t_2])\n",
    "    audios_cut.append(cut)\n",
    "    sf.write(\"data/audio/example_\"+titles[i]+\".wav\", cut, 44_100)\n",
    "\n",
    "display(Audio(np.sum(np.array(audios_cut), axis=0), rate=44100))\n",
    "for i, audio_ in enumerate(audios_cut):\n",
    "    display(Audio(audio_, rate=44100))\n",
    "    plt.figure()\n",
    "    plt.plot(t_cut, audio_)\n",
    "    plt.title(titles[i])\n",
    "    plt.ylabel(\"Sound amplitude\")\n",
    "    plt.xlabel(\"t[s]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Timbre Transfer (here as an example in Google Colab to not require DDSP implementation)\n",
    "# Then, load the timbre transformed files.\n",
    "# Trained DDSP Models are not provided (500 MByte per model). We can distribute them if desired.\n",
    "\n",
    "from audio2numpy import open_audio\n",
    "sound_flute_flute, sr = open_audio(\n",
    "    \"data/audio/example_flute_new_timbre_flute.wav\")\n",
    "sound_guitar_guitar, sr = open_audio(\n",
    "    \"data/audio/example_guitar_new_timbre_guitar.wav\")\n",
    "sound_trombone_horn, sr = open_audio(\n",
    "    \"data/audio/example_trombone_new_timbre_horn.wav\")\n",
    "sound_trumpet_trumpet, sr = open_audio(\n",
    "    \"data/audio/example_trumpet_new_timbre_trumpet.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine and play\n",
    "Audio(sound_flute_flute+sound_guitar_guitar+sound_guitar_guitar +\n",
    "      sound_trombone_horn+sound_trumpet_trumpet, rate=sr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be heard above, the output is not really natural even though a natural model was assumed.\n",
    "However, and that is one major learning, the sound of an instrument is not only defined by its timbre. Instead, artifacts arising from artificial oscillations lead to the strange sound that was generated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f0c48a2510500372683021a8da20ae8a85be53b22e7c072f2fffd3068dfe896b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
