{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Instrument Timbre Transfer using Omnizart and DDSP\n",
    "\n",
    "This notebook does illustrate how we combined those two pieces of software to\n",
    "create a multi-instrument timbre transfer system.\n",
    "\n",
    "This is a local version of the code that only runs on the CPU. Hence, it takes\n",
    "some time to run. Using a GPU lead to issues with Tensorflow on our local\n",
    "machine. You may try to use a GPU by commenting out the lines 7 to 10 in the\n",
    "cell just below. In parallel we also ran this code on the Scitas Izar cluster where we\n",
    "didn't have those issues but unfortunately the synthesizer software to resynthesize\n",
    "the midis generated bby Omnizart is not installable on the cluster. Thus, the\n",
    "workflow was rather unpractical involving downloading the midis, synthesizing\n",
    "them and then uploading those audio files back to the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omni_transcribe import transcribe, synth\n",
    "from ddsp_timbre_transfer import timbre_transfer\n",
    "from utils import combine_wavs, convert_wav\n",
    "import scipy.io.wavfile as wave\n",
    "\n",
    "# Disable GPU\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices(device_type = 'GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "file_path = \"data/1788_example.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we use Omnizart to perform source separation and transcribe the different\n",
    "instruments into separate midi files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 14:11:17 Loading model...\n",
      "2022-07-13 14:11:28 Extracting feature...\n",
      "2022-07-13 14:11:43 Predicting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 689ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 14:12:04 Inferring notes....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 14:12:06 MIDI file has been written to ./data/1788_example_0.mid.\n",
      "2022-07-13 14:12:06 MIDI file has been written to ./data/1788_example_1.mid.\n",
      "2022-07-13 14:12:06 MIDI file has been written to ./data/1788_example_2.mid.\n",
      "2022-07-13 14:12:06 MIDI file has been written to ./data/1788_example_3.mid.\n",
      "2022-07-13 14:12:06 Transcription finished\n"
     ]
    }
   ],
   "source": [
    "# Transcribe to midi\n",
    "midis = transcribe(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the midis must be resynthesized using a software synthesizer\n",
    "because DDSP takes wav files as input and not midis directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file as: ./data/1788_example_0_synth.wav\n",
      "Synthesizing MIDI...\n",
      "Synthesize finished\n",
      "Output file as: ./data/1788_example_1_synth.wav\n",
      "Synthesizing MIDI...\n",
      "Synthesize finished\n",
      "Output file as: ./data/1788_example_2_synth.wav\n",
      "Synthesizing MIDI...\n",
      "Synthesize finished\n",
      "Output file as: ./data/1788_example_3_synth.wav\n",
      "Synthesizing MIDI...\n",
      "Synthesize finished\n"
     ]
    }
   ],
   "source": [
    "# Synthesize midi to wav files\n",
    "for midi in midis:\n",
    "    synth(midi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to change the encoding of the wav files in order for them to be\n",
    "compatible with the DDSP code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavs = [midi[2:].replace(\".mid\",\"\")+\"_synth.wav\" for midi in midis]\n",
    "valid_wavs = [wav for wav in wavs if wave.read(wav)[1].size > 0]\n",
    "wavs_16bit = [wav.replace(\".wav\",\"_16.wav\") for wav in valid_wavs]\n",
    "\n",
    "pair = zip(valid_wavs, wavs_16bit)\n",
    "\n",
    "# Convert the encoding of the wav files\n",
    "for p in pair:\n",
    "    convert_wav(*p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, the timbre transfer enabled through DDSP is applied to each of\n",
    "the separated instruments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting audio features...\n",
      "Audio features took 204.7 seconds\n",
      "Loading dataset statistics from /home/nicolas/workspace/ma/ma4/ddspzart/workspace/ddsp_pretrained/solo_violin/dataset_statistics.pkl\n",
      "===Trained model===\n",
      "Time Steps 1000\n",
      "Samples 64000\n",
      "Hop Size 64\n",
      "\n",
      "===Resynthesis===\n",
      "Time Steps 7930\n",
      "Samples 507520\n",
      "\n",
      "Restoring model took 27.7 seconds\n",
      "Prediction took 15.7 seconds\n",
      "\n",
      "Extracting audio features...\n",
      "Audio features took 145.1 seconds\n",
      "Loading dataset statistics from /home/nicolas/workspace/ma/ma4/ddspzart/workspace/ddsp_pretrained/solo_flute/dataset_statistics.pkl\n",
      "===Trained model===\n",
      "Time Steps 1000\n",
      "Samples 64000\n",
      "Hop Size 64\n",
      "\n",
      "===Resynthesis===\n",
      "Time Steps 7635\n",
      "Samples 488640\n",
      "\n",
      "Restoring model took 14.8 seconds\n",
      "Prediction took 16.2 seconds\n",
      "\n",
      "Extracting audio features...\n",
      "Audio features took 186.7 seconds\n",
      "Loading dataset statistics from /home/nicolas/workspace/ma/ma4/ddspzart/workspace/ddsp_pretrained/solo_trumpet/dataset_statistics.pkl\n",
      "===Trained model===\n",
      "Time Steps 1000\n",
      "Samples 64000\n",
      "Hop Size 64\n",
      "\n",
      "===Resynthesis===\n",
      "Time Steps 8400\n",
      "Samples 537600\n",
      "\n",
      "Restoring model took 18.1 seconds\n",
      "Prediction took 15.3 seconds\n"
     ]
    }
   ],
   "source": [
    "# {\"Violin\", \"Flute\", \"Flute2\", \"Trumpet\", \"Tenor_Saxophone\"}\n",
    "all_instruments = [\"Violin\", \"Flute\", \"Trumpet\", \"Tenor_Saxophone\"]\n",
    "length_instr = len(all_instruments)\n",
    "instruments = [all_instruments[i % length_instr] for i in range(len(wavs_16bit))]\n",
    "\n",
    "pairs = zip(wavs_16bit, instruments)\n",
    "\n",
    "# Perform timbre transfer\n",
    "results = [timbre_transfer(wav, instrument) for wav, instrument in pairs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally those different audio files, each with a transferred timbre, are\n",
    "combined back into a single audio file, resulting in a timbre-transferred multi-\n",
    "instrument track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine wav files into one\n",
    "out_path = file_path.replace(\".wav\",\"_result.wav\")\n",
    "combine_wavs(results, out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f0c48a2510500372683021a8da20ae8a85be53b22e7c072f2fffd3068dfe896b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
